from typing import Collection

from opentelemetry.instrumentation.instrumentor import BaseInstrumentor
from opentelemetry.trace import get_tracer
from opentelemetry.metrics import get_meter
from apmplus_server.instrumentation.ark_runtime.chat_wrappers import chat_wrapper,achat_wrapper
from apmplus_server.sdk.utils.version import __version__
from apmplus_server.sdk.config import (
    is_metrics_enabled
)
from wrapt import wrap_function_wrapper


_instruments = ("ark >= 0.0.1",)


class ArkRuntimeInstrumentor(BaseInstrumentor):
    """An instrumentor for Ark Runtime."""

    def instrumentation_dependencies(self) -> Collection[str]:
        return _instruments

    def _instrument(self, **kwargs):
        tracer_provider = kwargs.get("tracer_provider")
        tracer = get_tracer(__name__, __version__, tracer_provider)
        # meter and counters are inited here
        meter_provider = kwargs.get("meter_provider")
        meter = get_meter(__name__, __version__, meter_provider)
        if is_metrics_enabled():
            chat_token_counter = meter.create_counter(
                name="llm.token.usage",
                unit="token",
                description="Number of tokens used in prompt and completions",
            )
            # chat_token_recoder = meter.create_observable_counter()
            chat_choice_counter = meter.create_counter(
                name="llm.chat_completions.choices",
                unit="choice",
                description="Number of choices returned by chat completions call",
            )

            chat_duration_histogram = meter.create_histogram(
                name="llm.chat_completions.duration",
                unit="ms",
                description="Duration of chat completion operation",
            )

            chat_exception_counter = meter.create_counter(
                name="llm.chat_completions.exceptions",
                unit="time",
                description="Number of exceptions occurred during chat completions",
            )

            streaming_time_to_first_token = meter.create_histogram(
                name="llm.chat_completions.streaming_time_to_first_token",
                unit="ms",
                description="Time to first token in streaming chat completions",
            )
            streaming_time_to_generate = meter.create_histogram(
                name="llm.chat_completions.streaming_time_to_generate",
                unit="ms",
                description="Time between first token and completion in streaming chat completions",
            )
            streaming_time_per_output_token = meter.create_histogram(
                name="llm.chat_completions.streaming_time_per_output_token",
                unit="ms",
                description="Time per output token in streaming chat completions",
            )
        else:
            (
                chat_token_counter,
                chat_choice_counter,
                chat_duration_histogram,
                chat_exception_counter,
                streaming_time_to_first_token,
                streaming_time_to_generate,
                streaming_time_per_output_token
            ) = (None, None, None, None, None, None, None)
        wrap_function_wrapper(
            "volcenginesdkarkruntime.resources.chat.completions",
            "AsyncCompletions.create",
            achat_wrapper(
                tracer,
                chat_token_counter,
                chat_choice_counter,
                chat_duration_histogram,
                chat_exception_counter,
                streaming_time_to_first_token,
                streaming_time_to_generate,
                streaming_time_per_output_token
            ),
        )
        wrap_function_wrapper(
            "volcenginesdkarkruntime.resources.chat.completions",
            "Completions.create",
            chat_wrapper(
                tracer,
                chat_token_counter,
                chat_choice_counter,
                chat_duration_histogram,
                chat_exception_counter,
                streaming_time_to_first_token,
                streaming_time_to_generate,
                streaming_time_per_output_token
            ),
        )
        # TODO: is resources.completions exist?
        # wrap_function_wrapper(
        #     "volcenginesdkarkruntime.resources.completions",
        #     "Completions.create",
        #     completion_wrapper(tracer),
        # )

    def _uninstrument(self, **kwargs):
        pass
