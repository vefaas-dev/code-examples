import os
import json
import logging
import volcenginesdkarkruntime
from importlib.metadata import version
from opentelemetry import context as context_api
from apmplus_server.sdk.semconv import SpanAttributes

ARK_LLM_USAGE_TOKEN_TYPES = ["prompt_tokens", "completion_tokens", "total_tokens"]


def should_send_prompts():
    return (
        os.getenv("ARK_TRACE_CONTENT") or "true"
    ).lower() == "true" or context_api.get_value("override_enable_content_tracing")


def _set_span_attribute(span, name, value):
    if value is not None:
        if value != "":
            span.set_attribute(name, value)
    return


def _set_functions_attributes(span, functions):
    if not functions:
        return

    for i, function in enumerate(functions):
        prefix = f"{SpanAttributes.LLM_REQUEST_FUNCTIONS}.{i}"
        _set_span_attribute(span, f"{prefix}.name", function.get("name"))
        _set_span_attribute(span, f"{prefix}.description", function.get("description"))
        _set_span_attribute(
            span, f"{prefix}.parameters", json.dumps(function.get("parameters"))
        )


def set_tools_attributes(span, tools):
    if not tools:
        return

    for i, tool in enumerate(tools):
        function = tool.get("function")
        if not function:
            continue

        prefix = f"{SpanAttributes.LLM_REQUEST_FUNCTIONS}.{i}"
        _set_span_attribute(span, f"{prefix}.name", function.get("name"))
        _set_span_attribute(span, f"{prefix}.description", function.get("description"))
        _set_span_attribute(
            span, f"{prefix}.parameters", json.dumps(function.get("parameters"))
        )


def _set_request_attributes(span, kwargs):
    if not span.is_recording():
        return

    try:
        # _set_api_attributes(span)
        _set_span_attribute(span, SpanAttributes.LLM_VENDOR, "ARK_RUNTIME")
        _set_span_attribute(span, SpanAttributes.LLM_REQUEST_MODEL, kwargs.get("model"))
        _set_span_attribute(
            span, SpanAttributes.LLM_REQUEST_MAX_TOKENS, kwargs.get("max_tokens")
        )
        _set_span_attribute(
            span, SpanAttributes.LLM_TEMPERATURE, kwargs.get("temperature")
        )
        _set_span_attribute(span, SpanAttributes.LLM_TOP_P, kwargs.get("top_p"))
        _set_span_attribute(
            span, SpanAttributes.LLM_FREQUENCY_PENALTY, kwargs.get("frequency_penalty")
        )
        _set_span_attribute(
            span, SpanAttributes.LLM_PRESENCE_PENALTY, kwargs.get("presence_penalty")
        )
        _set_span_attribute(span, SpanAttributes.LLM_USER, kwargs.get("user"))
        _set_span_attribute(
            span, SpanAttributes.LLM_HEADERS, str(kwargs.get("headers"))
        )
        _set_span_attribute(
            span, SpanAttributes.LLM_IS_STREAMING, kwargs.get("stream") or False
        )
    except Exception as ex:  # pylint: disable=broad-except
        logging.warning(
            "Failed to set input attributes for request span, error: %s", str(ex)
        )

def _set_response_attributes(span, response):
    if not span.is_recording():
        return

    try:
        _set_span_attribute(
            span, SpanAttributes.LLM_RESPONSE_MODEL, response.get("model")
        )

        usage = response.get("usage")
        if not usage:
            return

        if not isinstance(usage, dict):
            usage = usage.__dict__

        _set_span_attribute(
            span, SpanAttributes.LLM_USAGE_TOTAL_TOKENS, usage.get("total_tokens")
        )
        _set_span_attribute(
            span,
            SpanAttributes.LLM_USAGE_COMPLETION_TOKENS,
            usage.get("completion_tokens"),
        )
        _set_span_attribute(
            span, SpanAttributes.LLM_USAGE_PROMPT_TOKENS, usage.get("prompt_tokens")
        )

        return
    except Exception as ex:  # pylint: disable=broad-except
        logging.warning(
            "Failed to set response attributes for response span, error: %s", str(ex)
        )


def _get_ark_runtime_base_url(instance):
    if hasattr(instance, "_client"):
        client = instance._client  # pylint: disable=protected-access
        # TODO: get ark_runtime base url
        if isinstance(client, (volcenginesdkarkruntime.AsyncArk, volcenginesdkarkruntime.Ark)):
            return str(client._base_url)

    return ""


def is_streaming_response(response):
    # return true
    return isinstance(response, volcenginesdkarkruntime.Stream) or isinstance(
        response, volcenginesdkarkruntime.AsyncStream
    )


def model_as_dict(model):
    if version("pydantic") < "2.0.0":
        return model.dict()
    if hasattr(model, "model_dump"):
        return model.model_dump()
    elif hasattr(model, "parse"):  # Raw API response
        return model_as_dict(model.parse())
    else:
        return model
